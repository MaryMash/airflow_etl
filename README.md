# ETL для загрузки инкрементальных данных
### Стэк:
- Python 3.10
- Airflow  2.2.5
- PostgreSQL

### Задачи: 
- ежедневно получать данные по продажам по API;
- загружать данные в stage, учитывая что в данных могут быть изменения и дубликаты;
- обеспечить возможность перезапуска пайплайна в случае необходимости.

### Описание этапов пайплайна: 
1. **generate_report**
Отправляется запрос на создание отчета. API возвращает параметр `task_id`, который записывается в xcom.

2. **get_report**
Каждые 10 секунд запрашивается статус задачи по `task_id`. Если статус = 'SUCCESS', API возвращает параметр `report_id`, который записывается в xcom.

3. **get_increment**
Отправляется запрос с параметром `report_id` на получение данных за текущую дату. Файлы сохраняются в локальном хранилище. 

4. **sensors**
С помощью `FileSensor` проверяется наличие всех файлов. Если какой-то из файлов не был найден, процесс загрузки данных останавливается. 

5. **upload_inc_data_to_staging**
Из локального хранилища данные переносятся в staging-слой базы данных. 
В процессе загрузки: 
- из файлов удаляются дубликаты;
- для таблицы `user_order_log_inc` реализовано получение данных по новому параметру 'status'. Также обрабатывается случай, когда данные могут поступать без этого параметра;
- реализована возможность перезапуска пайплайна без появления дубликатов.
